%% -----------------------------------------------------------------
INTERFACE/COSMETIC CHANGES:

* cosmetic: unify underscores and capitalization in naming, at least
  for top-level (user-called) functions and variables!

* Clear global variables

* add figure size and position parameters to params.plotting
* add scroll bars to data plots

* add to params.plotting: maxTracePlotLen, noiseCol, spikeCol

* Seems that matlabpool is being phased out, and parpool is taking its
  place.  We need to update the code accordingly...

* Top-level function PreprocessTrace should be renamed WhitenTrace
  (but there's already another function with that name).
    
* In PreprocessTrace, show noise distribution after whitening, not
   before. Reasoning: need to whiten regardless of marginal
   distribution, so the only thing that's relevant is the
   post-whitening distribution

* VisualizeClustering
  - display of waveforms/traces for multi-electrodes is confusing
  - Show a black asterisk at the current waveforms (centroids)
  - give time in msec, not samples
  - show spike rates, in addition to total count
  - show multiple PC views (1 vs 2, 2 vs 3, 1 vs 3) ?
  - Give SNR, or d':  expected SDT error rate, given univariate Gaussian noise

* AmplitudeThresholdGUI:
  - give timescales in msec, not samples
  - show total spike counts (and rate) for each cell. 
  - clicking escape key should exit, choosing the automatic values
  - if general.plot_diagnostics is false, should just choose auto values

* After running CBP, provide GUI to click on amplitude, auto or
  cross-correlation and inspect the correpsonding data.  Specifically,
  user should be able to examine unusually large or small amplitude
  spikes, refractory violations, and synchrony artifacts.

* after clustering or CBP run, give options to:
  merge cells (average two waveforms, reduce num_waveforms)
  split cells (specify new centroids graphically, increase num_waveforms)
  add a new (orthogonalized) random waveform

* Why are there two functions, evaluate_sorting and EvaluateSorting ?  Yuk.

* In ground truth analysis, maybe state something like:
  "Found <Hit> of <Hit+Miss> true spikes, missed <Miss> (XX.X%), and misreported <FA> (**%) false positives"
   Standard to report: Recall: Hit/(Hit+Miss),  Precision: Hit/(Hit+FA) 

* Display stats in ground truth comparison figures (preserved if we try
  again with different params, increasing the starting figure number) ?

%% -----------------------------------------------------------------
SMALL ALGORITHMIC CHANGES:

* Data file should include a t0 (time of initial sample) and all times
  should be relative to that! But this requires computing/correcting
  filtering lags.

* waveform_len should be in msec, not in samples [yuk]
* default filter.freq should cover range of typical spike waveforms (in Hz)  

* clustering.percent_variance should be chosen automatically, based on estimated SNR.

* Consistency of thresholding test for spikes/noise: 
   X filtering globally rescales data so that max(abs) is 1.
   X whitening section compares cross-channel norm (CCN) to noise_threshold to find noise regions
   - clustering section compares 4*std(CCN) to grab spike segments - prefer chiMean+4*sqrt(chiVR).
     [should add a parameter, clustering.spike_threshold, for number of sds]
   - CBP chunking section: another threshold?

* rethink thresholding: shouldn't it be done based on WINDOWED L2
  norm?  Perhaps soft-max across electrodes of windowed norm?
  Windowed norm more robust than peak, and some cells may show up on a
  small subset of electrodes (so max is better).  To do this for the
  whitening stage, previous (filtering) step needs to get noise
  variance constant on electrodes.

* Consistency of waveform length?  Do we really need different
  parameters in the whitening, clustering, and CBP sections?

* filtering.pad shoudl be set automatically, and doesn't need to be a
  parameter.  Left side should be padded by filtering.order, and right
  side needs order+waveform_len, and a bit more for IIR filtering.

* Preprocessing step 4 - Partitioning (snippets):
  choose partion_pars.threshold based on sliding Lp-norm?
  The threshold should be the minimum window Lp-norm containing any overlap
  of any pair of waveforms. Display a histogram of sliding Lp-norms with
  this automated choice for the user.

* CBP Priors on firing rates (currently hard-coded) should be set
  based on clustering results

* Handle noise distributions with other pnorms (stretched
   exponentials) [NOTE: easy with cvx package, but hard to do with
   ecos]

%% -----------------------------------------------------------------
MAJOR ALGORITHM MODIFICATIONS:

* Spike intervals are currently identified for noise covariance
  estimation by thresholding the cross-channel norm.  For larger
  numbers of electrodes, it would be better to compute something like
  max (or Lp-norm for p large) over the L2 norm of localized subgroups
  of electrodes.  Basically, matched filtering, assuming cells show up
  on subsets of electrodes, and the noise is whitened. 

* Use an operator-splitting optimization method (e.g., ADMM) to embed
  the final thresholding step into the iterative process.

* Incremental method 